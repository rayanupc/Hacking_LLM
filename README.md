# HackingLLM

L'objectif de ce projet est de cr√©er un assistant (chatbot) sp√©cialis√© en cybers√©curit√© capable de fournir des r√©ponses techniques sans les restrictions de s√©curit√© natives, tout en optimisant le mod√®le pour une ex√©cution fluide.
Pour cela je pr√©sente ici une impl√©mentation de la technique d' "abliterration" appliqu√©e au mod√®le Llama-3.2-3B-Instruct. 

## Qu'est-ce que l'Abliterration ?
Le projet repose sur la m√©thode d√©crite par Maxime Labonne dans l'article [*Abliterating safety training from LLMs*](https://huggingface.co/blog/mlabonne/abliteration) Contrairement au fine-tuning classique qui n√©cessite un r√©entra√Ænement co√ªteux, l'abliterration est une technique de "chirurgie" des poids du mod√®le.

## M√©thodologie

### 1. Identification du "Vecteur de Refus"
Le principe est d'identifier dans l'espace latent du mod√®le une direction sp√©cifique qui correspond au comportement de refus.
* On compare les activations du mod√®le face √† deux jeux de donn√©es : des requ√™tes **harmful** (n√©fastes) et **harmless** (inoffensives).
* La diff√©rence de moyenne entre ces activations permet d'isoler un vecteur math√©matique : la **direction du refus**.

### 2. Orthogonalisation des Poids
Une fois cette direction identifi√©e, on modifie les matrices de poids du mod√®le (principalement les matrices de sortie des couches d'attention et MLP) pour les rendre **orthogonales** √† ce vecteur.
* Math√©matiquement, on "projette" les poids du mod√®le de mani√®re √† ce qu'ils ne puissent plus s'aligner sur la direction du refus.
* Le mod√®le conserve ses capacit√©s de raisonnement technique mais perd sa capacit√© √† d√©clencher un refus cat√©gorique.



---

## üõ†Ô∏è Application dans ce Projet

Dans ce d√©p√¥t, la m√©thode a √©t√© adapt√©e pour r√©pondre aux besoins sp√©cifiques de la recherche en cybers√©curit√© :

1.  **Cible** : Llama-3.2-3B-Instruct.
2.  **Modification** : Application de l'orthogonalisation sur les couches critiques (15 √† 24) pour maximiser l'efficacit√© sans d√©grader la coh√©rence du langage.
3.  **R√©sultat** : Un mod√®le capable de d√©tailler des vuln√©rabilit√©s critiques comme **PrintNightmare** sans message de refus moralisateur.

## ‚ö° Optimisation et Fluidit√© (Format GGUF)

Un d√©fi majeur de ce projet √©tait de faire tourner ce mod√®le de mani√®re fluide sur un **Mac Intel**.
* **Conversion GGUF** : Le mod√®le abliter√© a √©t√© converti du format Safetensors (6.4 Go) vers le format GGUF.
* **Quantification Q4_K_M** : Le mod√®le a √©t√© compress√© en 4-bit (~2.1 Go). Cette √©tape est cruciale car elle permet au mod√®le de tenir enti√®rement dans la RAM, passant d'un temps de r√©ponse de 30 minutes √† une g√©n√©ration fluide en temps r√©el.

---

## üöÄ Installation et Usage

### Pr√©requis
* [Ollama](https://ollama.com) install√© sur macOS ou Linux.

### Importation dans Ollama
Clonez ce d√©p√¥t, placez le fichier `.gguf` dans le dossier et lancez la cr√©ation du mod√®le :
```bash
ollama create llama3-cyber -f Modelfile

